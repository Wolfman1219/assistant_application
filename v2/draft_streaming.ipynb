{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef7d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0a94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM sysdefault\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.front\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround21\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround40\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround41\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround50\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround51\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.iec958\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_a52.c:1001:(_snd_pcm_a52_open) a52 is only for playback\n",
      "ALSA lib conf.c:5694:(snd_config_expand) Unknown parameters {AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM iec958:{AES0 0x6 AES1 0x82 AES2 0x0 AES3 0x2 CARD 0}\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:165:(snd_config_get_card) Cannot get card index for 0\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_card_id returned error: No such file or directory\n",
      "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1342:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:5204:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5727:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM dmix\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK = int(SAMPLE_RATE / 10)\n",
    "\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d6d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akbar/vad_train/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MyDatabase.SpeakerDiarization.MyProtocol' found in /home/akbar/vad_train/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"v5_1.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dafd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided by Alexander Veysov\n",
    "def int2float(sound):\n",
    "    abs_max = np.abs(sound).max()\n",
    "    sound = sound.astype('float32')\n",
    "    if abs_max > 0:\n",
    "        sound *= 1/32768\n",
    "    sound = sound.squeeze()  # depends on the use case\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d0b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_recording = True\n",
    "\n",
    "num_samples = 4096 * 2\n",
    "\n",
    "def stop():\n",
    "    input(\"Press Enter to stop the recording:\")\n",
    "    global continue_recording\n",
    "    continue_recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78644b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recording_sliding_window():\n",
    "    \n",
    "    stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=SAMPLE_RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    \n",
    "    global continue_recording\n",
    "    continue_recording = True\n",
    "        \n",
    "    stop_listener = threading.Thread(target=stop)\n",
    "    stop_listener.start()\n",
    "\n",
    "    audio_array = np.zeros(1)\n",
    "    duration, step =int(5.0 * SAMPLE_RATE), int(1.5 * SAMPLE_RATE)\n",
    "    current_point = 0\n",
    "\n",
    "    pred_list = [] \n",
    "    \n",
    "    start  = time.time()\n",
    "    while continue_recording:\n",
    "    \n",
    "        audio_chunk = stream.read(num_samples)\n",
    "        \n",
    "        audio_int16 = np.frombuffer(audio_chunk, np.int16)\n",
    "        audio_float32 = audio_int16.astype(np.float32) / 32767.0\n",
    "        # print(f\"Type: {type(audio_float32)}\\nSize: {len(audio_float32)}\")\n",
    "        \n",
    "        # audio_array at the end will contain wave array of whole audio\n",
    "        audio_array = audio_float32 if audio_array.shape[0] == 1 else np.concatenate((audio_array, audio_float32), axis=0)\n",
    "\n",
    "        if len(audio_array) - current_point < duration:\n",
    "            continue\n",
    "        \n",
    "        audio_torch = torch.from_numpy(audio_array[current_point:current_point+duration])\n",
    "        current_point += step\n",
    "\n",
    "        # print(\"Started\")\n",
    "        with torch.no_grad():\n",
    "            out = model(audio_torch.reshape(1, 1, -1)).squeeze(0, 2).numpy()\n",
    "            preds = (out >= 0.8)\n",
    "            pred_list.append(out)\n",
    "            print(f\"Prediction: {preds}\")\n",
    "    end = time.time()\n",
    "    \n",
    "    while current_point < len(audio_array):\n",
    "        audio_torch = torch.from_numpy(audio_array[current_point:current_point+duration])\n",
    "        current_point += step\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(audio_torch.reshape(1, 1, -1)).squeeze(0, 2).numpy()\n",
    "            preds = (out >= 0.8)\n",
    "            print(f\"Prediction: {preds}\")\n",
    "        \n",
    "    print(f\"duration: {(end - start):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311762f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "Prediction: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False]\n",
      "Prediction: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "Prediction: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False]\n",
      "Prediction: [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False]\n",
      "duration: 6.938\n"
     ]
    }
   ],
   "source": [
    "start_recording_sliding_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22685fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop():\n",
    "    input(\"Press Enter to stop the recording:\")\n",
    "    global continue_recording\n",
    "    continue_recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_recording():\n",
    "    \n",
    "    stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=SAMPLE_RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    \n",
    "    global continue_recording\n",
    "    continue_recording = True\n",
    "        \n",
    "    stop_listener = threading.Thread(target=stop)\n",
    "    stop_listener.start()\n",
    "\n",
    "    print(f\"Start\")\n",
    "    while continue_recording:\n",
    "    \n",
    "        audio_chunk = stream.read(num_samples)\n",
    "        \n",
    "        audio_int16 = np.frombuffer(audio_chunk, np.int16)\n",
    "        audio_float32 = audio_int16.astype(np.float32) / 32767.0        \n",
    "        audio_torch = torch.from_numpy(audio_float32)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            out = model(audio_torch.reshape(1, 1, -1)).squeeze(0, 2).numpy()\n",
    "            preds = (out >= 0.8)\n",
    "            print(f\"Prediction: {preds}\")\n",
    "            \n",
    "    print(f\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3c87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop():\n",
    "    input(\"Press Enter to stop the recording:\")\n",
    "    global continue_recording\n",
    "    continue_recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d92d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "[0.40134737 0.30128017 0.26434973 0.24874628 0.24212398 0.23672298\n",
      " 0.22469775 0.21374202 0.20991552 0.21309355 0.22539838 0.26033902]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     29\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m out\n\u001b[32m     30\u001b[39m             \u001b[38;5;66;03m# preds = (out >= 0.85)\u001b[39;00m\n\u001b[32m     31\u001b[39m             \u001b[38;5;66;03m# if preds.any(True):\u001b[39;00m\n\u001b[32m     32\u001b[39m             \u001b[38;5;66;03m#     print(f\"Prediction: {True}\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m         \u001b[38;5;66;03m# print(f\"End\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m        \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mstreamer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstreamer\u001b[39m():\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m continue_recording:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m         audio_chunk = \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(\u001b[32m4096\u001b[39m)\n\u001b[32m     24\u001b[39m         audio_int16 = np.frombuffer(audio_chunk, np.int16)\n\u001b[32m     25\u001b[39m         audio_float32 = audio_int16.astype(np.float32) / \u001b[32m32767.0\u001b[39m        \n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "    # parser = argparse.ArgumentParser(description='Create a voice activity detection dataset')\n",
    "    # parser.add_argument('--num_samples', type=int, default=512, help='Set Number of samples. Min is 4096')\n",
    "    # args = parser.parse_args()\n",
    "      \n",
    "stream = audio.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "global continue_recording\n",
    "continue_recording = True\n",
    "    \n",
    "stop_listener = threading.Thread(target=stop)\n",
    "stop_listener.start()\n",
    "\n",
    "print(f\"Start\")\n",
    "\n",
    "while continue_recording:\n",
    "\n",
    "    audio_chunk = stream.read(4096)\n",
    "    \n",
    "    audio_int16 = np.frombuffer(audio_chunk, np.int16)\n",
    "    audio_float32 = audio_int16.astype(np.float32) / 32767.0        \n",
    "    audio_torch = torch.from_numpy(audio_float32)\n",
    "    with torch.no_grad():\n",
    "        out = model(audio_torch.reshape(1, 1, -1)).squeeze(0, 2).numpy()\n",
    "        # yield out\n",
    "        preds = (out >= 0.85)\n",
    "        if preds.any(True):\n",
    "            print(f\"Prediction: {True}\")\n",
    "        else:\n",
    "            print(f\"Prediction: {False}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5fb542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "tensor([ 6.1037e-05, -1.8006e-03, -3.9979e-03, -3.1434e-03, -2.8382e-03,\n",
      "        -5.0050e-03, -7.1718e-03, -6.7751e-03, -4.1505e-03, -2.6551e-03,\n",
      "        -1.7090e-03,  1.8311e-04,  1.5870e-03,  1.2207e-03, -2.7467e-04,\n",
      "        -4.5778e-04,  3.9674e-04,  4.5778e-04, -4.5778e-04, -3.0519e-05,\n",
      "         1.0071e-03,  1.0071e-03,  1.2207e-03,  9.7659e-04,  1.0681e-03,\n",
      "         1.9532e-03,  1.5870e-03,  1.3733e-03,  2.1058e-03,  1.7090e-03,\n",
      "         1.2207e-03,  1.8006e-03,  3.4486e-03,  4.6999e-03,  5.1576e-03,\n",
      "         6.2868e-03,  6.1647e-03,  4.3947e-03,  3.7843e-03,  3.2960e-03,\n",
      "         1.6175e-03,  1.0376e-03,  1.8311e-03,  2.9603e-03,  4.6693e-03,\n",
      "         5.7375e-03,  4.8219e-03,  3.2960e-03,  2.0447e-03,  0.0000e+00,\n",
      "        -1.9837e-03, -2.3194e-03, -1.7701e-03, -1.1902e-03, -1.0987e-03,\n",
      "        -7.3244e-04, -6.7141e-04, -1.6785e-03, -2.8993e-03, -3.7538e-03,\n",
      "        -4.1810e-03, -4.6693e-03, -4.6388e-03, -4.1505e-03, -3.4791e-03,\n",
      "        -2.6551e-03, -2.1363e-03, -2.2889e-03, -2.6246e-03, -3.2044e-03,\n",
      "        -3.8759e-03, -4.3641e-03, -4.9135e-03, -4.6693e-03, -4.0590e-03,\n",
      "        -3.0824e-03, -1.5259e-03, -6.7141e-04, -3.0519e-05,  1.0071e-03,\n",
      "         1.8311e-03,  2.3499e-03,  1.7396e-03,  7.9348e-04,  7.0193e-04,\n",
      "         2.7467e-04, -3.0519e-05,  1.8311e-04,  6.1037e-04,  1.3123e-03,\n",
      "         1.8311e-03,  1.9837e-03,  1.8921e-03,  1.6785e-03,  1.8006e-03,\n",
      "         2.0753e-03,  1.7090e-03,  1.8311e-03,  2.5330e-03,  2.8687e-03,\n",
      "         3.2044e-03,  2.9298e-03,  2.5025e-03,  2.1363e-03,  1.0071e-03,\n",
      "         3.0519e-05, -5.1881e-04, -9.1556e-04, -7.6296e-04, -1.8311e-04,\n",
      "         5.1881e-04,  1.5564e-03,  2.2584e-03,  1.8006e-03,  6.4089e-04,\n",
      "        -4.2726e-04, -1.6480e-03, -3.1434e-03, -3.9674e-03, -3.4486e-03,\n",
      "        -2.6246e-03, -1.9532e-03, -6.1037e-04,  3.3570e-04,  4.2726e-04,\n",
      "         6.7141e-04,  6.1037e-04,  6.1037e-04,  9.4607e-04,  4.2726e-04,\n",
      "        -1.8311e-04,  6.4089e-04,  2.0753e-03,  1.5870e-03,  1.0987e-03,\n",
      "         1.9532e-03,  1.5870e-03,  1.1597e-03,  1.0681e-03, -3.3570e-04,\n",
      "        -8.8504e-04, -4.5778e-04, -8.8504e-04, -1.4039e-03, -9.4607e-04,\n",
      "        -3.0519e-05,  4.8830e-04,  7.9348e-04,  8.5452e-04, -3.0519e-05,\n",
      "        -1.3733e-03, -2.1973e-03, -2.5636e-03, -2.4415e-03, -1.4039e-03,\n",
      "         9.1556e-05,  5.7985e-04,  3.0519e-05,  0.0000e+00, -9.1556e-05,\n",
      "        -1.1292e-03, -2.3194e-03, -2.2279e-03, -1.4649e-03, -1.6175e-03,\n",
      "        -1.3428e-03, -6.1037e-05,  3.3570e-04,  6.1037e-04,  7.9348e-04,\n",
      "        -1.5259e-04, -2.7467e-04,  0.0000e+00, -4.2726e-04, -1.0071e-03,\n",
      "        -8.8504e-04, -4.2726e-04, -5.1881e-04, -3.6622e-04, -1.8311e-04,\n",
      "        -4.2726e-04, -5.1881e-04, -2.1363e-04, -1.5259e-04, -3.9674e-04,\n",
      "        -7.3244e-04, -1.2513e-03, -1.7090e-03, -1.4954e-03, -1.2207e-03,\n",
      "        -1.2818e-03, -1.2818e-03, -8.8504e-04, -5.7985e-04, -2.7467e-04,\n",
      "         2.4415e-04, -9.1556e-05, -3.6622e-04, -1.2207e-04,  2.7467e-04,\n",
      "         5.7985e-04,  7.9348e-04,  1.1292e-03,  1.1902e-03,  1.0681e-03,\n",
      "         7.9348e-04,  5.4933e-04,  3.9674e-04,  2.4415e-04,  9.1556e-05,\n",
      "         5.1881e-04,  1.4039e-03,  1.6785e-03,  1.7701e-03,  1.8311e-03,\n",
      "         1.3428e-03,  4.5778e-04, -3.9674e-04, -1.1292e-03, -1.9227e-03,\n",
      "        -1.8006e-03, -1.1292e-03, -7.0193e-04, -4.5778e-04, -3.0519e-04,\n",
      "        -2.7467e-04, -6.1037e-05,  2.1363e-04, -9.1556e-05,  1.8311e-04,\n",
      "         2.7467e-04, -3.3570e-04, -3.6622e-04, -5.7985e-04, -5.7985e-04,\n",
      "        -4.5778e-04, -6.1037e-04, -8.2400e-04, -1.1902e-03, -1.2207e-03,\n",
      "        -9.7659e-04, -6.4089e-04,  9.1556e-05,  7.6296e-04,  1.0987e-03,\n",
      "         1.5870e-03,  1.8311e-03,  1.5870e-03,  1.7090e-03,  1.2818e-03,\n",
      "         3.6622e-04,  4.2726e-04,  6.1037e-04,  7.6296e-04,  9.7659e-04,\n",
      "         1.0987e-03,  1.5870e-03,  1.8616e-03,  2.0142e-03,  1.8311e-03,\n",
      "         1.4344e-03,  1.2818e-03,  8.5452e-04,  4.5778e-04,  5.4933e-04,\n",
      "         4.2726e-04,  3.0519e-05, -9.1556e-05, -5.7985e-04, -1.3428e-03,\n",
      "        -1.7701e-03, -2.0142e-03, -1.9227e-03, -1.7090e-03, -1.8006e-03,\n",
      "        -1.7396e-03, -1.2818e-03, -1.1597e-03, -1.2818e-03, -1.4954e-03,\n",
      "        -1.9227e-03, -2.2279e-03, -1.8311e-03, -1.4954e-03, -1.4649e-03,\n",
      "        -1.1292e-03, -9.7659e-04, -7.6296e-04, -3.6622e-04, -5.4933e-04,\n",
      "        -1.0071e-03, -1.1597e-03, -1.0376e-03, -5.1881e-04,  1.5259e-04,\n",
      "         6.7141e-04,  6.1037e-04,  2.4415e-04,  0.0000e+00, -5.7985e-04,\n",
      "        -1.1597e-03, -1.3733e-03, -1.5259e-03, -1.0987e-03, -3.3570e-04,\n",
      "        -1.8311e-04, -3.0519e-05,  1.5259e-04, -1.8311e-04, -3.6622e-04,\n",
      "        -3.0519e-05,  3.9674e-04,  4.8830e-04,  3.3570e-04,  3.6622e-04,\n",
      "         7.0193e-04,  6.4089e-04,  1.5259e-04, -2.1363e-04, -4.5778e-04,\n",
      "         0.0000e+00,  4.8830e-04,  3.3570e-04,  4.5778e-04,  5.4933e-04,\n",
      "         7.3244e-04,  1.2818e-03,  1.3428e-03,  1.2818e-03,  1.2818e-03,\n",
      "         7.3244e-04,  3.0519e-04, -3.0519e-05, -6.7141e-04, -7.9348e-04,\n",
      "        -5.4933e-04, -2.4415e-04, -3.0519e-05,  1.2207e-04,  4.5778e-04,\n",
      "         6.4089e-04,  6.1037e-04,  3.9674e-04,  3.3570e-04,  5.4933e-04,\n",
      "         3.9674e-04,  1.2207e-04,  1.2207e-04, -3.0519e-05,  6.1037e-05,\n",
      "         1.8311e-04,  1.2207e-04,  3.6622e-04,  6.1037e-04,  7.0193e-04,\n",
      "         7.9348e-04,  6.1037e-04,  4.8830e-04,  5.4933e-04,  2.7467e-04,\n",
      "         3.9674e-04,  7.0193e-04,  8.5452e-04,  1.0071e-03,  3.9674e-04,\n",
      "         0.0000e+00,  3.6622e-04,  8.5452e-04,  1.0376e-03,  1.0987e-03,\n",
      "         1.7090e-03,  2.0753e-03,  1.8006e-03,  1.3123e-03,  1.1292e-03,\n",
      "         1.2207e-03,  1.5564e-03,  1.8616e-03,  1.8921e-03,  1.7090e-03,\n",
      "         1.2207e-03,  9.7659e-04,  4.8830e-04, -3.0519e-05,  9.1556e-05,\n",
      "         3.6622e-04,  4.5778e-04,  1.8311e-04,  0.0000e+00, -3.0519e-04,\n",
      "        -7.0193e-04, -7.9348e-04, -1.1597e-03, -1.2513e-03, -8.2400e-04,\n",
      "        -8.8504e-04, -1.1597e-03, -1.0376e-03, -7.9348e-04, -8.2400e-04,\n",
      "        -1.0681e-03, -1.1597e-03, -1.1597e-03, -1.3123e-03, -1.1597e-03,\n",
      "        -8.8504e-04, -1.0071e-03, -1.0681e-03, -8.5452e-04, -9.4607e-04,\n",
      "        -1.4039e-03, -1.4649e-03, -9.7659e-04, -1.8311e-04,  2.1363e-04,\n",
      "         1.5259e-04, -6.1037e-05, -2.1363e-04, -2.1363e-04, -3.9674e-04,\n",
      "        -7.3244e-04, -5.4933e-04, -2.1363e-04,  3.0519e-05,  3.3570e-04,\n",
      "         1.2207e-04, -3.9674e-04, -6.4089e-04, -4.5778e-04, -1.2207e-04,\n",
      "        -3.0519e-05, -1.5259e-04, -6.1037e-05,  1.8311e-04,  3.3570e-04,\n",
      "        -6.1037e-05, -2.7467e-04, -3.0519e-05, -3.6622e-04, -2.7467e-04,\n",
      "         3.6622e-04,  7.9348e-04,  1.1597e-03,  1.3733e-03,  1.1902e-03,\n",
      "         1.0681e-03,  1.0071e-03,  8.2400e-04,  7.0193e-04,  7.9348e-04,\n",
      "         1.0376e-03,  1.0987e-03,  1.2818e-03,  1.5564e-03,  1.5564e-03,\n",
      "         1.4039e-03,  1.4039e-03,  1.4344e-03,  1.3123e-03,  1.1292e-03,\n",
      "         7.9348e-04,  2.4415e-04, -2.1363e-04, -1.2207e-04,  2.4415e-04,\n",
      "         3.9674e-04,  4.8830e-04,  5.1881e-04,  2.7467e-04,  3.0519e-05,\n",
      "        -4.2726e-04, -7.6296e-04, -7.6296e-04, -6.1037e-04, -6.4089e-04,\n",
      "        -8.2400e-04, -8.5452e-04, -7.9348e-04, -8.8504e-04, -1.2207e-03,\n",
      "        -1.2513e-03, -9.7659e-04, -7.6296e-04, -6.4089e-04, -5.1881e-04,\n",
      "        -3.3570e-04,  0.0000e+00,  1.8311e-04, -6.1037e-05, -3.0519e-05,\n",
      "         3.0519e-04,  5.4933e-04,  8.5452e-04,  1.1292e-03,  1.3733e-03,\n",
      "         1.7396e-03,  2.0447e-03,  2.1058e-03,  2.0447e-03,  2.1668e-03,\n",
      "         2.0447e-03,  1.6480e-03,  1.4954e-03,  1.5870e-03,  2.0447e-03,\n",
      "         2.2889e-03,  1.9227e-03,  1.7396e-03,  1.6785e-03,  1.3123e-03,\n",
      "         9.1556e-04,  6.1037e-04])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 spatial element when training, got input size torch.Size([1, 60, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(audio_torch)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_torch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m).numpy()\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[32m     30\u001b[39m     preds = (out >= \u001b[32m0.85\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/pyannote/audio/models/segmentation/PyanNet.py:223\u001b[39m, in \u001b[36mPyanNet.forward\u001b[39m\u001b[34m(self, waveforms)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveforms: torch.Tensor) -> torch.Tensor:\n\u001b[32m    212\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Pass forward\u001b[39;00m\n\u001b[32m    213\u001b[39m \n\u001b[32m    214\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m \u001b[33;03m    scores : (batch, frame, classes)\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msincnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hparams.lstm[\u001b[33m\"\u001b[39m\u001b[33mmonolithic\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    226\u001b[39m         outputs, _ = \u001b[38;5;28mself\u001b[39m.lstm(\n\u001b[32m    227\u001b[39m             rearrange(outputs, \u001b[33m\"\u001b[39m\u001b[33mbatch feature frame -> batch frame feature\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    228\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/pyannote/audio/models/blocks/sincnet.py:182\u001b[39m, in \u001b[36mSincNet.forward\u001b[39m\u001b[34m(self, waveforms)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c == \u001b[32m0\u001b[39m:\n\u001b[32m    180\u001b[39m         outputs = torch.abs(outputs)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     outputs = F.leaky_relu(\u001b[43mnorm1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:124\u001b[39m, in \u001b[36m_InstanceNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[38;5;28mself\u001b[39m._get_no_batch_dim():\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_no_batch_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_instance_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:47\u001b[39m, in \u001b[36m_InstanceNorm._apply_instance_norm\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply_instance_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/functional.py:2875\u001b[39m, in \u001b[36minstance_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[39m\n\u001b[32m   2862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2863\u001b[39m         instance_norm,\n\u001b[32m   2864\u001b[39m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2872\u001b[39m         eps=eps,\n\u001b[32m   2873\u001b[39m     )\n\u001b[32m   2874\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_input_stats:\n\u001b[32m-> \u001b[39m\u001b[32m2875\u001b[39m     \u001b[43m_verify_spatial_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.instance_norm(\n\u001b[32m   2877\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2878\u001b[39m     weight,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2885\u001b[39m     torch.backends.cudnn.enabled,\n\u001b[32m   2886\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vad_train/env/lib/python3.12/site-packages/torch/nn/functional.py:2841\u001b[39m, in \u001b[36m_verify_spatial_size\u001b[39m\u001b[34m(size)\u001b[39m\n\u001b[32m   2839\u001b[39m     size_prods *= size[i]\n\u001b[32m   2840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_prods == \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2841\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2842\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected more than 1 spatial element when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2843\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Expected more than 1 spatial element when training, got input size torch.Size([1, 60, 1])"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ad1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
